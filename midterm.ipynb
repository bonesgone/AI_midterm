{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEBM4FsnHexsZMGrfp9D2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonesgone/AI_midterm/blob/main/midterm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def generate_sequential_data(num_samples, sequence_length, fault_probability):\n",
        "    # Initialize empty lists to store the generated data\n",
        "    data_list = []\n",
        "\n",
        "    # Define parameters for data generation\n",
        "    normal_parameters = {\n",
        "        'temperature_mean': 60,\n",
        "        'temperature_stddev': 5,\n",
        "        'vibration_mean': 0.1,\n",
        "        'vibration_stddev': 0.02,\n",
        "        'load_mean': 500,\n",
        "        'load_stddev': 50,\n",
        "        'speed_mean': 2,\n",
        "        'speed_stddev': 0.1,\n",
        "    }\n",
        "\n",
        "    fault_parameters = {\n",
        "        'temperature_mean': 80,\n",
        "        'temperature_stddev': 10,\n",
        "        'vibration_mean': 0.5,\n",
        "        'vibration_stddev': 0.1,\n",
        "        'load_mean': 700,\n",
        "        'load_stddev': 100,\n",
        "        'speed_mean': 1.5,\n",
        "        'speed_stddev': 0.2,\n",
        "    }\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        is_fault = np.random.choice([0, 1], p=[1 - fault_probability, fault_probability])\n",
        "        parameters = fault_parameters if is_fault else normal_parameters\n",
        "\n",
        "        # Generate a sequence of data\n",
        "        timestamp = pd.date_range(start='2023-01-01', periods=sequence_length, freq='H')\n",
        "        temperature = np.random.normal(parameters['temperature_mean'], parameters['temperature_stddev'], sequence_length)\n",
        "        vibration = np.random.normal(parameters['vibration_mean'], parameters['vibration_stddev'], sequence_length)\n",
        "        load_value = np.random.normal(parameters['load_mean'], parameters['load_stddev'], sequence_length)\n",
        "        speed_value = np.random.normal(parameters['speed_mean'], parameters['speed_stddev'], sequence_length)\n",
        "\n",
        "        # Append the generated data to the list\n",
        "        data = {\n",
        "            'Timestamp': timestamp,\n",
        "            'Temperature': temperature,\n",
        "            'Vibration': vibration,\n",
        "            'Load': load_value,\n",
        "            'Speed': speed_value,\n",
        "            'IsFaulty': is_fault\n",
        "        }\n",
        "        data_list.append(data)\n",
        "\n",
        "    # Create a DataFrame to store the generated data\n",
        "    data = pd.DataFrame(data_list)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Usage example:\n",
        "num_samples = 100  # Number of sequences to generate\n",
        "sequence_length = 24  # Length of each sequence (e.g., 24 hours of data)\n",
        "fault_probability = 0.05  # Probability of a fault occurring\n",
        "simulated_data = generate_sequential_data(num_samples, sequence_length, fault_probability)\n",
        "print(simulated_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpBhw-fvVHsE",
        "outputId": "abbf7a80-c11e-432d-9eb8-bf4eb685c39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Timestamp  \\\n",
            "0  DatetimeIndex(['2023-01-01 00:00:00', '2023-01...   \n",
            "1  DatetimeIndex(['2023-01-01 00:00:00', '2023-01...   \n",
            "2  DatetimeIndex(['2023-01-01 00:00:00', '2023-01...   \n",
            "3  DatetimeIndex(['2023-01-01 00:00:00', '2023-01...   \n",
            "4  DatetimeIndex(['2023-01-01 00:00:00', '2023-01...   \n",
            "\n",
            "                                         Temperature  \\\n",
            "0  [54.63148970620763, 65.65125082158785, 57.6592...   \n",
            "1  [58.9507232472633, 53.95590527932745, 60.66305...   \n",
            "2  [54.75021165698568, 61.33285204437739, 60.2988...   \n",
            "3  [58.9396119741823, 57.125414099987175, 57.8583...   \n",
            "4  [71.74799959729197, 52.248495480923154, 67.737...   \n",
            "\n",
            "                                           Vibration  \\\n",
            "0  [0.11171967483791354, 0.08819227286477428, 0.0...   \n",
            "1  [0.09001807397153416, 0.12735570969786647, 0.1...   \n",
            "2  [0.1009791346806206, 0.1383252262240254, 0.088...   \n",
            "3  [0.09707568030517838, 0.09006359951054106, 0.0...   \n",
            "4  [0.13832894115720934, 0.10036364374900095, 0.1...   \n",
            "\n",
            "                                                Load  \\\n",
            "0  [528.2443328268807, 523.6257057152968, 471.976...   \n",
            "1  [496.12225900237087, 466.56587512023435, 515.1...   \n",
            "2  [545.2768756234553, 457.54936601918973, 511.47...   \n",
            "3  [483.48805453263304, 538.6695488674492, 441.36...   \n",
            "4  [461.34763035938624, 421.00419416754676, 529.4...   \n",
            "\n",
            "                                               Speed  IsFaulty  \n",
            "0  [2.133931863974916, 2.0127149230582537, 2.0985...         0  \n",
            "1  [2.067362879263808, 1.8446082590302184, 1.8675...         0  \n",
            "2  [2.0777257185285034, 2.175117656462606, 1.9006...         0  \n",
            "3  [1.9664723464346534, 1.949586757781343, 2.0300...         0  \n",
            "4  [2.137049883879362, 1.9061483958271013, 1.9945...         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def generate_sequential_data(num_samples, sequence_length, start_date, sensor_parameters, fault_probability):\n",
        "    \"\"\"\n",
        "    Generate synthetic sequential data for conveyor belts.\n",
        "\n",
        "    Parameters:\n",
        "    - num_samples: Number of data sequences to generate.\n",
        "    - sequence_length: Length of each data sequence (e.g., number of time steps).\n",
        "    - start_date: The starting date for the data sequences.\n",
        "    - sensor_parameters: A dictionary containing parameters for sensor data generation.\n",
        "\n",
        "    Returns:\n",
        "    - A Pandas DataFrame containing the generated data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize empty lists to store the generated data\n",
        "    timestamps = []\n",
        "    temperatures = []\n",
        "    vibrations = []\n",
        "    belt_speeds = []\n",
        "    is_faults = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate a sequence of data\n",
        "        is_fault = np.random.choice([0, 1], p=[1 - fault_probability, fault_probability])\n",
        "        timestamp = pd.date_range(start=start_date, periods=sequence_length, freq='H')\n",
        "        temperature = np.random.normal(sensor_parameters['temperature_mean'], sensor_parameters['temperature_stddev'], sequence_length)\n",
        "        vibration = np.random.normal(sensor_parameters['vibration_mean'], sensor_parameters['vibration_stddev'], sequence_length)\n",
        "        belt_speed = np.random.normal(sensor_parameters['belt_speed_mean'], sensor_parameters['belt_speed_stddev'], sequence_length)\n",
        "\n",
        "        # Append the generated data to the lists\n",
        "        timestamps.append(timestamp)\n",
        "        temperatures.append(temperature)\n",
        "        vibrations.append(vibration)\n",
        "        belt_speeds.append(belt_speed)\n",
        "        is_faults.append(is_fault)\n",
        "\n",
        "    # Create a DataFrame to store the generated data\n",
        "    data = pd.DataFrame({\n",
        "        'Timestamp': [item for sublist in timestamps for item in sublist],\n",
        "        'Temperature': [item for sublist in temperatures for item in sublist],\n",
        "        'Vibration': [item for sublist in vibrations for item in sublist],\n",
        "        'BeltSpeed': [item for sublist in belt_speeds for item in sublist],\n",
        "    })\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage:\n",
        "num_samples = 100  # Number of data sequences to generate\n",
        "sequence_length = 24  # Length of each sequence (e.g., 24 hours of data)\n",
        "start_date = '2023-01-01'\n",
        "sensor_parameters = {\n",
        "    'temperature_mean': 60,\n",
        "    'temperature_stddev': 5,\n",
        "    'vibration_mean': 0.1,\n",
        "    'vibration_stddev': 0.02,\n",
        "    'belt_speed_mean': 2,\n",
        "    'belt_speed_stddev': 0.1\n",
        "}\n",
        "\n",
        "fault_probability = 0.05  # Probability of a fault occurring in a sequence\n",
        "simulated_data = generate_sequential_data(num_samples, sequence_length, start_date, sensor_parameters, fault_probability)\n",
        "print(simulated_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlTD3Fk4eIkN",
        "outputId": "8442a0df-5073-41ab-9204-32226ef77f62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Timestamp  Temperature  Vibration  BeltSpeed\n",
            "0 2023-01-01 00:00:00    58.151930   0.116356   2.021461\n",
            "1 2023-01-01 01:00:00    65.671994   0.122462   1.866770\n",
            "2 2023-01-01 02:00:00    60.779252   0.060294   1.882181\n",
            "3 2023-01-01 03:00:00    62.261867   0.070519   2.061353\n",
            "4 2023-01-01 04:00:00    51.678694   0.093586   2.071619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "msv7Yqto9pKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocess_sequential_data(data, target_column, test_size=0.2, random_state=None):\n",
        "    \"\"\"\n",
        "    Preprocess the generated sequential data by scaling and splitting it into training and testing sets.\n",
        "\n",
        "    Parameters:\n",
        "    - data: The Pandas DataFrame containing the generated data.\n",
        "    - target_column: The name of the target column to predict.\n",
        "    - test_size: The proportion of data to include in the test split (default is 0.2).\n",
        "    - random_state: Seed for the random number generator for reproducibility (default is None).\n",
        "\n",
        "    Returns:\n",
        "    - X_train: The training features.\n",
        "    - X_test: The testing features.\n",
        "    - y_train: The training target.\n",
        "    - y_test: The testing target.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract the features (input) and the target (output) column\n",
        "    X = data.drop(columns=[target_column])\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Scale the features using StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# Generate some example sequential data\n",
        "num_samples = 100\n",
        "sequence_length = 24\n",
        "fault_probability = 0.05\n",
        "\n",
        "# Specify the name of the target column\n",
        "target_column = 'IsFaulty'\n",
        "\n",
        "# Preprocess the data and split it into training and testing sets\n",
        "X_train, X_test, y_train, y_test = preprocess_sequential_data(simulated_data, target_column, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "VlppoNcvjzOm",
        "outputId": "62011979-592f-4f6c-bd06-6b4bcd2c84c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-75a02641a1bf>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Preprocess the data and split it into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sequential_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulated_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-75a02641a1bf>\u001b[0m in \u001b[0;36mpreprocess_sequential_data\u001b[0;34m(data, target_column, test_size, random_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Extract the features (input) and the target (output) column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5397\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5398\u001b[0m         \"\"\"\n\u001b[0;32m-> 5399\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5400\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5401\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6934\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6935\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['IsFaulty'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Create a Sequential model\n",
        "model = tf.keras.Sequential ([\n",
        "tf.keras.layers.SimpleRNN(128, activation = 'relu' ,\n",
        "         return_sequences = True , input_shape =(28 , 28) ) ,\n",
        "    tf.keras.layers.SimpleRNN(64, activation = 'relu') ,\n",
        "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "def train_lstm_model(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
        "    \"\"\"\n",
        "    Train the LSTM model using training data and evaluate its performance on the testing data.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The compiled LSTM model.\n",
        "    - X_train: The training features.\n",
        "    - y_train: The training target.\n",
        "    - X_test: The testing features.\n",
        "    - y_test: The testing target.\n",
        "    - epochs: The number of training epochs (default is 10).\n",
        "    - batch_size: The batch size for training (default is 32).\n",
        "\n",
        "    Returns:\n",
        "    - history: The training history with loss and accuracy metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the testing data\n",
        "    evaluation = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # Print evaluation results (e.g., loss and accuracy)\n",
        "    print(\"Evaluation results:\")\n",
        "    print(f\"Loss: {evaluation[0]}, Accuracy: {evaluation[1]}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# Example usage:\n",
        "epochs = 10  # Specify the number of training epochs\n",
        "batch_size = 32  # Specify the batch size for training\n",
        "\n",
        "# Train the LSTM model\n",
        "training_history = train_lstm_model(model, X_train, y_train, X_test, y_test, epochs, batch_size)\n"
      ],
      "metadata": {
        "id": "oYq0jYYHlsMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "ebd8357f-d870-4f7f-9bbc-741641eef8d2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9001c30ae745>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Train the LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "2w2lVB3hs4aN",
        "outputId": "70e56539-46ef-4598-b5ec-ed9a485d9210"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f90301ce5b61>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Train the LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}